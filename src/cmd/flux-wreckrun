#!/usr/bin/env lua

-------------------------------------------------------------------------------
-- Modules:
-------------------------------------------------------------------------------
local flux = require 'flux'
local posix = require 'flux.posix'
local timer = require 'flux.timer'

local prog = string.match (arg[0], "([^/]+)$")
local shortprog = prog:match ("flux%-(.+)$")

--
-- Termination state needs to remain a global for access from
--  signal handler functions. See setup_signal_handlers() below.
--
terminate = false

-------------------------------------------------------------------------------
-- Local functions:
-------------------------------------------------------------------------------
--
--  Check that parameter [a] is an integer --
local function is_integer (a)
    local b = tonumber (a)
    return (type (b) == "number") and (math.floor(b) == b)
end

---
--  Get the LWJ return code as highest of all task return codes
---
local function lwj_return_code (f, wreck, id)
    local max, msgs = wreck.status { flux = f, jobid = id }
    local fn = getmetatable (wreck) [ max > 0 and "say" or "verbose" ]
    for s,h in pairs (msgs) do
        fn (wreck, "task%s %s: %s\n", #h > 1 and "s" or "", tostring (h:sort()), s)
    end
    return max
end

--
-- Helper for fake_R_lite(): generate a fake range string from 0 .. n,
--  when n >= 1
--
local function range_string (n)
    if not n or n == 0 then return nil end
    local s = "0"
    if n > 1 then
        s = s .. "-" .. n-1
    end
    return s
end

--
-- Generate a fake R_lite representation for the current wreck request.
--  If -g, --gpus-per-task was used on the command line, include GPUs.
--
-- This assists with testing without sched or with the -I, --immediate flag.
--
local function fake_R_lite (f, wreck)
    local ncores, ngpus = wreck.ncores, wreck.ngpus
    local R_lite = {}
    local nnodes = wreck.nnodes > 0 and wreck.nnodes or f.size
    local cores_per_node = math.ceil (ncores / nnodes)
    local gpus_per_node =  ngpus and math.ceil (ngpus / nnodes)

    -- Allocate cores (and gpus) to R_lite in rank order until
    --  no more cores are required
    --
    for rank = 0, nnodes - 1 do
        local corecnt = math.min (ncores, cores_per_node)
        local gpucnt  = ngpus and math.min (wreck.ngpus, gpus_per_node)
        table.insert (R_lite, { rank = rank,
                                children = {
                                   core = range_string (corecnt),
                                   gpu  = range_string (gpucnt) }
                              })
        ncores = ncores - corecnt
        if ngpus then
            ngpus = ngpus - gpucnt
        end
        if ncores == 0 then
            return R_lite
        end
    end
    return R_lite
end

local function jobid_R_lite (f, wreck, id)
    local p = require 'wreck'.id_to_path { flux = f, jobid = tonumber (id) }
    local lwj, err = f:kvsdir (p)
    if not lwj then
        wreck:die ("Unable to fetch R_lite for jobid %d: %s\n", id, err)
    end
    return lwj.R_lite
end

local function wreckrun_hooks_compile (wreck)
    local code = wreck:getopt ("P")
    local pre_launch_fn = nil
    if code then
        wreck:verbose ("compiling code '%s'\n", code)
        pre_launch_fn, err = loadstring ("local wreck, lwj = ...; " .. code)
        if not pre_launch_fn then
            wreck:die ("--pre-launch-hook: %s\n", err)
        end
    end
    -- Add a hooks table to existing 'wreck' object
    wreck.hooks = { pre_launch = pre_launch_fn }
    return true
end

local function wreckrun_pre_launch ( wreck, lwj)
    if wreck.hooks.pre_launch then
        local r, v = pcall (wreck.hooks.pre_launch, wreck, lwj)
	if not r then return nil, v end
    end
    return true
end

-------------------------------------------------------------------------------
-- Main program:
-------------------------------------------------------------------------------
--  Open connection to flux broker:

local f, err = flux.new ()
if not f then
    io.stderr:write ("Unable to connect to flux broker: "..err)
    os.exit (1)
end

--  Parse cmdline args:
--
local wreck = require 'wreck' .new { prog = shortprog, flux = f }
local ioattach = require 'wreck'.ioattach
local logstream = require 'wreck'.logstream
local taskio
local log
local sigtimer
local state = ""

wreck:add_options ({
    { name = 'pre-launch-hook', char = "P", arg = "CODE",
        usage = "execute Lua CODE before launch." },
    { name = 'detach', char = "d",
        usage = "Detach immediately after starting job" },
    { name = 'wait-until', char = "w", arg = "STATE",
        usage = "Do not process stdio, but block until 'STATE'" },
    { name = 'immediate', char = "I",
        usage = "Bypass scheduler and run immediately" },
    { name = 'jobid', char = "J", arg = "ID",
        usage = "Run 1 process per rank across ranks of jobid" },
})

if not wreck:parse_cmdline (arg) then
    wreck:die ("Failed to process cmdline args\n")
end

-- Set --immediate if --jobid used
if wreck:getopt ('J') then wreck:setopt ('I') end

-- if nokz is in effect and the --output option is not used, AND
--  either --detach or --wait-until are active, then store output by
--  default in the kvs; o/w it is just dropped:
if (wreck.job_options.nokz and not wreck:getopt ('O')) and
   (wreck:getopt ('d') or wreck:getopt ('w')) then
    wreck.opts.O = "kvs://files.stdout"
    if not wreck:getopt ('E') then wreck.opts.E = "kvs://files.stderr" end

    -- Regenerate wreck.output output file configuration:
    wreck.output = wreck:output_file_config ()
end

wreckrun_hooks_compile (wreck)

-- Start in-program timer:
local tt = timer.new()

--
--  Create a new job in kvs
--
local jobid, err = wreck:createjob ()
if not jobid then wreck:die ("%s\n", err) end

wreck:verbose ("%4.03fs: Registered jobid %d\n", tt:get0(), jobid)

local jobid_fd = tonumber (os.getenv ("FLUX_WRECKRUN_JOBID_FD"))
if jobid_fd then
    posix.write (jobid_fd, jobid.."\n")
    posix.close (jobid_fd)
end

--
--  Get a handle to this lwj kvsdir:
--
local lwj, err = wreck:kvsdir (jobid)
if not lwj then wreck:die ("f:kvsdir(lwj.%d): %s\n", jobid, err) end

--
--  Check if job state is "complete" and all IO from tasks have closed:
--
local function check_job_completed ()
    if state == "failed" then
       log:dump()
       wreck:die ("job %d failed\n", jobid)
    end
    if (not taskio or taskio:complete()) and
       (state == "completing" or state == "complete" or state == "reaped") then
        local rc = lwj_return_code (f, wreck, jobid)
        if rc == 0 then
            wreck:verbose ("%.3fs: All tasks completed successfully.\n",
                           tt:get0 ());
        end
        os.exit (rc)
    end
end

---
--- Attach stdio kz streams and start all watchers
---
local function wreck_attach_stdio (wreck)
  --
  --  Open output to all tasks:
  --
  taskio, err = ioattach {
     flux = f,
     jobid = jobid,
     ntasks = wreck.ntasks,
     labelio = wreck.opts.l,
     nokz = wreck.job_options.nokz,
     ioservices = wreck.ioservices,
     on_completion = check_job_completed
  }
  if not taskio then wreck:die ("error opening task io: %s\n", err) end

  --
  --  Open stdin
  --
  local kz, err = f:kz_open (tostring (lwj)..".input.files.stdin", "w")
  if not kz then wreck:die (err) end

  --
  --  Add a file descriptor iowatcher for this script's stdin:
  --
  local iow, err = f:iowatcher {
    fd = posix.fileno (io.input()),
    handler = function (iow, data)
        if data.data then kz:write (data.data) end
        if data.eof  then kz:close ()          end
    end
  }
  if not iow then wreck:die ("error opening stdin: %s\n", err) end

  return taskio
end


--
--  Install watcher for this job's state before issuing any run request,
--  (So that no state events are missed)
--
local kw, err = f:kvswatcher  {
    key = string.format ("%s.state", wreck:lwj_path (jobid)),
    handler = function (kw, result)
        if result then
            state = result
            wreck:verbose ("%-4.03fs: State = %s\n", tt:get0(), result)
            if wreck.opts.w and state == wreck.opts.w then
                os.exit (0)
            end
            check_job_completed ()
        end
    end
}
if not kw then wreck:die ("kvs watch: %s\n", err) end

local submitted = false
if not wreck:getopt ("I") then
    -- Attempt to submit this existing job via submit-nocreate RPC:
    --
    local rc, err = f:rpc ("job.submit-nocreate", { jobid = jobid })
    if rc then
        submitted = true
        wreck:verbose ("%-4.03fs: job.submit: Success\n", tt:get0());
    else
        wreck:verbose ("%-4.03fs: job.submit: %s\n", tt:get0(), err)
    end
end

if not submitted then
    --
    --  If submit failed due to lack of scheduler or use of the
    --   -I, --immediate option, manually create R_lite and
    ---  send event to run the job.
    --

    --  If --jobid used then copy R_lite for targetted job and
    --   set ntasks equal to the number of ranks (unless overridden
    --   by --ntasks), otherwise create a fake R_lite:
    --
    local id = tonumber (wreck:getopt ("J"))
    local R_lite = nil
    if id then
        R_lite = jobid_R_lite (f, wreck, id)
        wreck.ntasks  = wreck:getopt ('n') or #R_lite
    else
        R_lite = fake_R_lite (f, wreck);
    end
    if not R_lite then wreck:die ("Failed to generate R_lite\n") end
    lwj.R_lite = R_lite
    lwj:commit()

    -- Ensure lwj nnodes matches fake allocation
    lwj.nnodes = tonumber (wreck.nnodes)
    lwj.ntasks = tonumber (wreck.ntasks)

    -- Execute any pre-launch hooks
    local r, err = wreckrun_pre_launch (wreck, lwj)
    if not r then
	lwj.state = "failed"
        lwj:commit()
        wreck:die ("pre-launch-hook failed: %s", err)
    end

    lwj:commit ()

    -- Now send run event:
    wreck:verbose ("%-4.03fs: Sending run event\n", tt:get0())
    local rc,err = f:sendevent ("wrexec.run.%d", jobid)
    if not rc then wreck:die ("sendevent: %s\n", err) end
    if wreck.opts.d then
        print (jobid)
        os.exit(0)
    end
end

-- Only process stdio if no --wait-until option used
if not wreck.opts.w then
    taskio = wreck_attach_stdio (wreck)
end

log, err = logstream {
     flux = f,
     jobid = jobid,
}
if not log then wreck:die ("error opening log stream: %s\n", err) end

local s, err = f:sighandler {
    sigmask = { posix.SIGINT, posix.SIGTERM },
    handler = function (f, s, sig)
        terminate = true
        f:reactor_stop ()
    end
}

local s, err = f:sighandler {
    sigmask = { posix.SIGALRM },
    handler = function (f, s, sig)
        wreck:say ("Killed by SIGALRM: state = %s\n", state)
        os.exit (128+posix.SIGALRM)
    end
}

--
--  Begin reactor loop:
--
local sigtimer = nil

repeat
    local r, err = f:reactor()
    if not r then wreck:die ("flux_reactor: %s", err) end
    --
    --  If we catch a signal then lwj:watch() will be interrupted.
    --   Check to see if we should terminate the job now:
    --
    if terminate then
        wreck:verbose ("%4.03fs: Killing LWJ %d\n", tt:get0(), jobid)
        local rc,err = f:sendevent ("wreck.%d.kill", jobid)
        if not rc then
            wreck:say ("Error: Failed to send kill event: %s", err)
        end
        if not sigtimer then
            sigtimer = timer.new()
            sigtimer:get()
        elseif sigtimer:get() < 1.0 then
            wreck:say ("Detaching from job. Processes may still be running\n");
            os.exit (0);
        end
        terminate = false
    end
until false


-- vi: ts=4 sw=4 expandtab
